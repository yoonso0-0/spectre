<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - 102d152bb208d020115bc267fd9f132d57025466 - DataStructures/Tensor/Expressions/TensorExpression.hpp</title>
  <link rel="stylesheet" type="text/css" href="../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title"> SpECTRE Documentation Coverage Report</td></tr>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../index.html">top level</a> - <a href="index.html">DataStructures/Tensor/Expressions</a> - TensorExpression.hpp</td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
             <td class="headerItem">Commit:</td>
             <td class="headerValue"><a target="_blank" href="https://github.com/sxs-collaboration/spectre/commit/102d152bb208d020115bc267fd9f132d57025466">102d152bb208d020115bc267fd9f132d57025466</a></td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">20</td>
            <td class="headerCovTableEntry">58</td>
            <td class="headerCovTableEntryLo">34.5 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-01-05 20:09:09</td>
            <td></td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
</td>
            <td></td>
          </tr>
          <tr><td><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span><span class="lineCov">          1 : // Distributed under the MIT License.</span></a>
<a name="2"><span class="lineNum">       2 </span>            : // See LICENSE.txt for details.</a>
<a name="3"><span class="lineNum">       3 </span>            : </a>
<a name="4"><span class="lineNum">       4 </span>            : /// \file</a>
<a name="5"><span class="lineNum">       5 </span>            : /// Defines class</a>
<a name="6"><span class="lineNum">       6 </span>            : </a>
<a name="7"><span class="lineNum">       7 </span>            : #pragma once</a>
<a name="8"><span class="lineNum">       8 </span>            : </a>
<a name="9"><span class="lineNum">       9 </span>            : #include &lt;array&gt;</a>
<a name="10"><span class="lineNum">      10 </span>            : #include &lt;cstddef&gt;</a>
<a name="11"><span class="lineNum">      11 </span>            : </a>
<a name="12"><span class="lineNum">      12 </span>            : #include &quot;DataStructures/Tensor/Structure.hpp&quot;</a>
<a name="13"><span class="lineNum">      13 </span>            : #include &quot;ErrorHandling/Assert.hpp&quot;  // IWYU pragma: keep</a>
<a name="14"><span class="lineNum">      14 </span>            : #include &quot;Utilities/Algorithm.hpp&quot;</a>
<a name="15"><span class="lineNum">      15 </span>            : #include &quot;Utilities/ForceInline.hpp&quot;</a>
<a name="16"><span class="lineNum">      16 </span>            : #include &quot;Utilities/Requires.hpp&quot;</a>
<a name="17"><span class="lineNum">      17 </span>            : #include &quot;Utilities/TMPL.hpp&quot;</a>
<a name="18"><span class="lineNum">      18 </span>            : #include &quot;Utilities/TypeTraits/IsA.hpp&quot;  // IWYU pragma: keep</a>
<a name="19"><span class="lineNum">      19 </span>            : </a>
<a name="20"><span class="lineNum">      20 </span>            : // The below values are used to separate upper indices from lower indices and</a>
<a name="21"><span class="lineNum">      21 </span>            : // spatial indices from spacetime indices.</a>
<a name="22"><span class="lineNum">      22 </span>            : //</a>
<a name="23"><span class="lineNum">      23 </span>            : // Tensor expressions perform as many calculations as possible in a constexpr</a>
<a name="24"><span class="lineNum">      24 </span>            : // context, which means working with fundamental types, specifically integer</a>
<a name="25"><span class="lineNum">      25 </span>            : // types, is easiest. By using sentinel values defined in one location we can</a>
<a name="26"><span class="lineNum">      26 </span>            : // easily control the encoding without having magic values floating around in</a>
<a name="27"><span class="lineNum">      27 </span>            : // many places. Furthermore, encoding all the information in the `size_t` means</a>
<a name="28"><span class="lineNum">      28 </span>            : // that when a failure occurs in one of the constexpr calculations it is</a>
<a name="29"><span class="lineNum">      29 </span>            : // reasonably easy to debug because, while encoded, the full type information is</a>
<a name="30"><span class="lineNum">      30 </span>            : // present. This approach can effectively be thought of as using specific bits</a>
<a name="31"><span class="lineNum">      31 </span>            : // in the `size_t` to mark information, using the size_t more as a bitfield than</a>
<a name="32"><span class="lineNum">      32 </span>            : // anything else. For human readability, we use base-10 numbers instead of</a>
<a name="33"><span class="lineNum">      33 </span>            : // base-2 values that would truly set individual bits.</a>
<a name="34"><span class="lineNum">      34 </span>            : //</a>
<a name="35"><span class="lineNum">      35 </span>            : // Spacetime indices are represented by values [0, `spatial_sentinel`) and</a>
<a name="36"><span class="lineNum">      36 </span>            : // spatial indices are represented by values</a>
<a name="37"><span class="lineNum">      37 </span>            : // [`spatial_sentinel`, `max_sentinel`). Lower spacetime indices are represented</a>
<a name="38"><span class="lineNum">      38 </span>            : // by values [0, `upper_sentinel`), and upper spacetime indices are represented</a>
<a name="39"><span class="lineNum">      39 </span>            : // by values [`upper_sentinel`, `spatial_sentinel`). Lower spatial indices are</a>
<a name="40"><span class="lineNum">      40 </span>            : // represented by values</a>
<a name="41"><span class="lineNum">      41 </span>            : // [`spatial_sentinel`, `spatial_sentinel` + `upper_sentinel`), and upper</a>
<a name="42"><span class="lineNum">      42 </span>            : // spatial indices are represented by values</a>
<a name="43"><span class="lineNum">      43 </span>            : // [`spatial_sentinel` + `upper_sentinel`, `max_sentinel`). Values equal to or</a>
<a name="44"><span class="lineNum">      44 </span>            : // above `max_sentinel` are considered invalid for representing an index.</a>
<a name="45"><span class="lineNum">      45 </span><span class="lineNoCov">          0 : static constexpr size_t spatial_sentinel = 1000;</span></a>
<a name="46"><span class="lineNum">      46 </span><span class="lineNoCov">          0 : static constexpr size_t upper_sentinel = 500;</span></a>
<a name="47"><span class="lineNum">      47 </span><span class="lineNoCov">          0 : static constexpr size_t upper_spatial_sentinel =</span></a>
<a name="48"><span class="lineNum">      48 </span>            :     spatial_sentinel + upper_sentinel;</a>
<a name="49"><span class="lineNum">      49 </span><span class="lineNoCov">          0 : static constexpr size_t max_sentinel = 2000;</span></a>
<a name="50"><span class="lineNum">      50 </span>            : </a>
<a name="51"><span class="lineNum">      51 </span>            : /*!</a>
<a name="52"><span class="lineNum">      52 </span>            :  * \ingroup TensorExpressionsGroup</a>
<a name="53"><span class="lineNum">      53 </span>            :  * \brief Represents the indices in a TensorExpression</a>
<a name="54"><span class="lineNum">      54 </span>            :  *</a>
<a name="55"><span class="lineNum">      55 </span>            :  * \details</a>
<a name="56"><span class="lineNum">      56 </span>            :  * Used to denote a tensor index in a tensor slot. This allows the following</a>
<a name="57"><span class="lineNum">      57 </span>            :  * type of expressions to work:</a>
<a name="58"><span class="lineNum">      58 </span>            :  * \code{.cpp}</a>
<a name="59"><span class="lineNum">      59 </span>            :  * auto T = evaluate&lt;ti_a, ti_b&gt;(F(ti_a, ti_b) + S(ti_b, ti_a));</a>
<a name="60"><span class="lineNum">      60 </span>            :  * \endcode</a>
<a name="61"><span class="lineNum">      61 </span>            :  * where `decltype(ti_a) == TensorIndex&lt;0&gt;` and</a>
<a name="62"><span class="lineNum">      62 </span>            :  * `decltype(ti_b) == TensorIndex&lt;1&gt;`. That is, `ti_a` and `ti_b` are</a>
<a name="63"><span class="lineNum">      63 </span>            :  * placeholders for objects of type `TensorIndex&lt;0&gt;` and `TensorIndex&lt;1&gt;`,</a>
<a name="64"><span class="lineNum">      64 </span>            :  * respectively.</a>
<a name="65"><span class="lineNum">      65 </span>            :  */</a>
<a name="66"><span class="lineNum">      66 </span>            : template &lt;std::size_t I, Requires&lt;(I &lt; max_sentinel)&gt; = nullptr&gt;</a>
<a name="67"><span class="lineNum">      67 </span><span class="lineCov">          1 : struct TensorIndex {</span></a>
<a name="68"><span class="lineNum">      68 </span><span class="lineNoCov">          0 :   using value_type = std::size_t;</span></a>
<a name="69"><span class="lineNum">      69 </span><span class="lineNoCov">          0 :   using type = TensorIndex&lt;I&gt;;</span></a>
<a name="70"><span class="lineNum">      70 </span><span class="lineNoCov">          0 :   static constexpr value_type value = I;</span></a>
<a name="71"><span class="lineNum">      71 </span><span class="lineNoCov">          0 :   static constexpr UpLo valence =</span></a>
<a name="72"><span class="lineNum">      72 </span>            :       ((I &lt; upper_sentinel) or</a>
<a name="73"><span class="lineNum">      73 </span>            :        (I &gt;= spatial_sentinel and I &lt; upper_spatial_sentinel))</a>
<a name="74"><span class="lineNum">      74 </span>            :           ? UpLo::Lo</a>
<a name="75"><span class="lineNum">      75 </span>            :           : UpLo::Up;</a>
<a name="76"><span class="lineNum">      76 </span><span class="lineNoCov">          0 :   static constexpr bool is_spacetime = I &lt; spatial_sentinel;</span></a>
<a name="77"><span class="lineNum">      77 </span>            : };</a>
<a name="78"><span class="lineNum">      78 </span>            : </a>
<a name="79"><span class="lineNum">      79 </span>            : /*!</a>
<a name="80"><span class="lineNum">      80 </span>            :  * \ingroup TensorExpressionsGroup</a>
<a name="81"><span class="lineNum">      81 </span>            :  * \brief Returns the TensorIndex value of with opposite valence.</a>
<a name="82"><span class="lineNum">      82 </span>            :  *</a>
<a name="83"><span class="lineNum">      83 </span>            :  * \details The input value represents a TensorIndex value, which encodes</a>
<a name="84"><span class="lineNum">      84 </span>            :  * both the valence of the index and whether the index is spacetime or</a>
<a name="85"><span class="lineNum">      85 </span>            :  * spatial. This function returns the value that corresponds to the encoding of</a>
<a name="86"><span class="lineNum">      86 </span>            :  * the TensorIndex with the same index type, but opposite valence.</a>
<a name="87"><span class="lineNum">      87 </span>            :  *</a>
<a name="88"><span class="lineNum">      88 </span>            :  * For example, 0 is the TensorIndex value for `ti_a`. If `i == 0`, then 500</a>
<a name="89"><span class="lineNum">      89 </span>            :  * will be returned, which is the TensorIndex value for `ti_A`. If `i == 500`</a>
<a name="90"><span class="lineNum">      90 </span>            :  * (representing `ti_A`), then 0 (representing `ti_a`) is returned.</a>
<a name="91"><span class="lineNum">      91 </span>            :  *</a>
<a name="92"><span class="lineNum">      92 </span>            :  * @param i a TensorIndex value that represents a generic index</a>
<a name="93"><span class="lineNum">      93 </span>            :  * @return the TensorIndex value that encodes the generic index with the</a>
<a name="94"><span class="lineNum">      94 </span>            :  * opposite valence</a>
<a name="95"><span class="lineNum">      95 </span>            :  */</a>
<a name="96"><span class="lineNum">      96 </span>            : SPECTRE_ALWAYS_INLINE static constexpr size_t</a>
<a name="97"><span class="lineNum">      97 </span><span class="lineCov">          1 : get_tensorindex_value_with_opposite_valence(const size_t i) noexcept {</span></a>
<a name="98"><span class="lineNum">      98 </span>            :   assert(i &lt; max_sentinel);  // NOLINT</a>
<a name="99"><span class="lineNum">      99 </span>            :   if ((i &gt;= upper_sentinel and i &lt; spatial_sentinel) or</a>
<a name="100"><span class="lineNum">     100 </span>            :       (i &gt;= upper_spatial_sentinel)) {</a>
<a name="101"><span class="lineNum">     101 </span>            :     // `i` represents an upper index, so return the lower index's encoding</a>
<a name="102"><span class="lineNum">     102 </span>            :     return i - upper_sentinel;</a>
<a name="103"><span class="lineNum">     103 </span>            :   } else {</a>
<a name="104"><span class="lineNum">     104 </span>            :     // `i` represents a lower index, so return the upper index's encoding</a>
<a name="105"><span class="lineNum">     105 </span>            :     return i + upper_sentinel;</a>
<a name="106"><span class="lineNum">     106 </span>            :   }</a>
<a name="107"><span class="lineNum">     107 </span>            : }</a>
<a name="108"><span class="lineNum">     108 </span>            : </a>
<a name="109"><span class="lineNum">     109 </span>            : // @{</a>
<a name="110"><span class="lineNum">     110 </span>            : /*!</a>
<a name="111"><span class="lineNum">     111 </span>            :  * \ingroup TensorExpressionsGroup</a>
<a name="112"><span class="lineNum">     112 </span>            :  * \brief The available TensorIndex's to use in a TensorExpression</a>
<a name="113"><span class="lineNum">     113 </span>            :  *</a>
<a name="114"><span class="lineNum">     114 </span>            :  * Available tensor indices to use in a Tensor Expression.</a>
<a name="115"><span class="lineNum">     115 </span>            :  * \snippet Test_AddSubtract.cpp use_tensor_index</a>
<a name="116"><span class="lineNum">     116 </span>            :  */</a>
<a name="117"><span class="lineNum">     117 </span><span class="lineCov">          1 : static constexpr TensorIndex&lt;0&gt; ti_a{};</span></a>
<a name="118"><span class="lineNum">     118 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel&gt; ti_A{};</span></a>
<a name="119"><span class="lineNum">     119 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;1&gt; ti_b{};</span></a>
<a name="120"><span class="lineNum">     120 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel + 1&gt; ti_B{};</span></a>
<a name="121"><span class="lineNum">     121 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;2&gt; ti_c{};</span></a>
<a name="122"><span class="lineNum">     122 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel + 2&gt; ti_C{};</span></a>
<a name="123"><span class="lineNum">     123 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;3&gt; ti_d{};</span></a>
<a name="124"><span class="lineNum">     124 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel + 3&gt; ti_D{};</span></a>
<a name="125"><span class="lineNum">     125 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;4&gt; ti_e{};</span></a>
<a name="126"><span class="lineNum">     126 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel + 4&gt; ti_E{};</span></a>
<a name="127"><span class="lineNum">     127 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;5&gt; ti_f{};</span></a>
<a name="128"><span class="lineNum">     128 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel + 5&gt; ti_F{};</span></a>
<a name="129"><span class="lineNum">     129 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;6&gt; ti_g{};</span></a>
<a name="130"><span class="lineNum">     130 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel + 6&gt; ti_G{};</span></a>
<a name="131"><span class="lineNum">     131 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;7&gt; ti_h{};</span></a>
<a name="132"><span class="lineNum">     132 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_sentinel + 7&gt; ti_H{};</span></a>
<a name="133"><span class="lineNum">     133 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;spatial_sentinel&gt; ti_i{};</span></a>
<a name="134"><span class="lineNum">     134 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_spatial_sentinel&gt; ti_I{};</span></a>
<a name="135"><span class="lineNum">     135 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;spatial_sentinel + 1&gt; ti_j{};</span></a>
<a name="136"><span class="lineNum">     136 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_spatial_sentinel + 1&gt; ti_J{};</span></a>
<a name="137"><span class="lineNum">     137 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;spatial_sentinel + 2&gt; ti_k{};</span></a>
<a name="138"><span class="lineNum">     138 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_spatial_sentinel + 2&gt; ti_K{};</span></a>
<a name="139"><span class="lineNum">     139 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;spatial_sentinel + 3&gt; ti_l{};</span></a>
<a name="140"><span class="lineNum">     140 </span><span class="lineNoCov">          0 : static constexpr TensorIndex&lt;upper_spatial_sentinel + 3&gt; ti_L{};</span></a>
<a name="141"><span class="lineNum">     141 </span>            : // @}</a>
<a name="142"><span class="lineNum">     142 </span>            : </a>
<a name="143"><span class="lineNum">     143 </span><span class="lineCov">          1 : namespace tt {</span></a>
<a name="144"><span class="lineNum">     144 </span>            : /*!</a>
<a name="145"><span class="lineNum">     145 </span>            :  * \ingroup TypeTraitsGroup TensorExpressionsGroup</a>
<a name="146"><span class="lineNum">     146 </span>            :  * \brief Check if a type `T` is a TensorIndex used in TensorExpressions</a>
<a name="147"><span class="lineNum">     147 </span>            :  */</a>
<a name="148"><span class="lineNum">     148 </span>            : template &lt;typename T&gt;</a>
<a name="149"><span class="lineNum">     149 </span><span class="lineCov">          1 : struct is_tensor_index : std::false_type {};</span></a>
<a name="150"><span class="lineNum">     150 </span>            : template &lt;size_t I&gt;</a>
<a name="151"><span class="lineNum">     151 </span><span class="lineNoCov">          0 : struct is_tensor_index&lt;TensorIndex&lt;I&gt;&gt; : std::true_type {};</span></a>
<a name="152"><span class="lineNum">     152 </span>            : }  // namespace tt</a>
<a name="153"><span class="lineNum">     153 </span>            : </a>
<a name="154"><span class="lineNum">     154 </span>            : namespace detail {</a>
<a name="155"><span class="lineNum">     155 </span>            : template &lt;typename State, typename Element, typename LHS&gt;</a>
<a name="156"><span class="lineNum">     156 </span>            : struct rhs_elements_in_lhs_helper {</a>
<a name="157"><span class="lineNum">     157 </span>            :   using type = std::conditional_t&lt;not std::is_same&lt;tmpl::index_of&lt;LHS, Element&gt;,</a>
<a name="158"><span class="lineNum">     158 </span>            :                                                    tmpl::no_such_type_&gt;::value,</a>
<a name="159"><span class="lineNum">     159 </span>            :                                   tmpl::push_back&lt;State, Element&gt;, State&gt;;</a>
<a name="160"><span class="lineNum">     160 </span>            : };</a>
<a name="161"><span class="lineNum">     161 </span>            : }  // namespace detail</a>
<a name="162"><span class="lineNum">     162 </span>            : </a>
<a name="163"><span class="lineNum">     163 </span>            : /// \ingroup TensorExpressionsGroup</a>
<a name="164"><span class="lineNum">     164 </span>            : /// Returns a list of all the elements in the typelist Rhs that are also in the</a>
<a name="165"><span class="lineNum">     165 </span>            : /// typelist Lhs.</a>
<a name="166"><span class="lineNum">     166 </span>            : ///</a>
<a name="167"><span class="lineNum">     167 </span>            : /// \details</a>
<a name="168"><span class="lineNum">     168 </span>            : /// Given two typelists `Lhs` and `Rhs`, returns a typelist of all the elements</a>
<a name="169"><span class="lineNum">     169 </span>            : /// in `Rhs` that are also in `Lhs` in the same order that they are in the</a>
<a name="170"><span class="lineNum">     170 </span>            : /// `Rhs`.</a>
<a name="171"><span class="lineNum">     171 </span>            : ///</a>
<a name="172"><span class="lineNum">     172 </span>            : /// ### Usage</a>
<a name="173"><span class="lineNum">     173 </span>            : /// For typelists `List1` and `List2`,</a>
<a name="174"><span class="lineNum">     174 </span>            : /// \code{.cpp}</a>
<a name="175"><span class="lineNum">     175 </span>            : /// using result = rhs_elements_in_lhs&lt;List1, List2&gt;;</a>
<a name="176"><span class="lineNum">     176 </span>            : /// \endcode</a>
<a name="177"><span class="lineNum">     177 </span>            : /// \metareturns</a>
<a name="178"><span class="lineNum">     178 </span>            : /// typelist</a>
<a name="179"><span class="lineNum">     179 </span>            : ///</a>
<a name="180"><span class="lineNum">     180 </span>            : /// \semantics</a>
<a name="181"><span class="lineNum">     181 </span>            : /// If `Lhs = tmpl::list&lt;A, B, C, D&gt;` and `Rhs = tmpl::list&lt;B, E, A&gt;`, then</a>
<a name="182"><span class="lineNum">     182 </span>            : /// \code{.cpp}</a>
<a name="183"><span class="lineNum">     183 </span>            : /// result = tmpl::list&lt;B, A&gt;;</a>
<a name="184"><span class="lineNum">     184 </span>            : /// \endcode</a>
<a name="185"><span class="lineNum">     185 </span>            : template &lt;typename Lhs, typename Rhs&gt;</a>
<a name="186"><span class="lineNum">     186 </span><span class="lineCov">          1 : using rhs_elements_in_lhs =</span></a>
<a name="187"><span class="lineNum">     187 </span>            :     tmpl::fold&lt;Rhs, tmpl::list&lt;&gt;,</a>
<a name="188"><span class="lineNum">     188 </span>            :                detail::rhs_elements_in_lhs_helper&lt;tmpl::_state, tmpl::_element,</a>
<a name="189"><span class="lineNum">     189 </span>            :                                                   tmpl::pin&lt;Lhs&gt;&gt;&gt;;</a>
<a name="190"><span class="lineNum">     190 </span>            : </a>
<a name="191"><span class="lineNum">     191 </span>            : namespace detail {</a>
<a name="192"><span class="lineNum">     192 </span>            : template &lt;typename Element, typename Iteration, typename Lhs, typename Rhs,</a>
<a name="193"><span class="lineNum">     193 </span>            :           typename RhsWithOnlyLhs, typename IndexInLhs&gt;</a>
<a name="194"><span class="lineNum">     194 </span>            : struct generate_transformation_helper {</a>
<a name="195"><span class="lineNum">     195 </span>            :   using tensor_index_to_find = tmpl::at&lt;RhsWithOnlyLhs, IndexInLhs&gt;;</a>
<a name="196"><span class="lineNum">     196 </span>            :   using index_to_replace_with = tmpl::index_of&lt;Rhs, tensor_index_to_find&gt;;</a>
<a name="197"><span class="lineNum">     197 </span>            :   using type = tmpl::size_t&lt;index_to_replace_with::value&gt;;</a>
<a name="198"><span class="lineNum">     198 </span>            : };</a>
<a name="199"><span class="lineNum">     199 </span>            : </a>
<a name="200"><span class="lineNum">     200 </span>            : template &lt;typename Element, typename Iteration, typename Lhs, typename Rhs,</a>
<a name="201"><span class="lineNum">     201 </span>            :           typename RhsWithOnlyLhs&gt;</a>
<a name="202"><span class="lineNum">     202 </span>            : struct generate_transformation_helper&lt;Element, Iteration, Lhs, Rhs,</a>
<a name="203"><span class="lineNum">     203 </span>            :                                       RhsWithOnlyLhs, tmpl::no_such_type_&gt; {</a>
<a name="204"><span class="lineNum">     204 </span>            :   using type = tmpl::size_t&lt;Iteration::value&gt;;</a>
<a name="205"><span class="lineNum">     205 </span>            : };</a>
<a name="206"><span class="lineNum">     206 </span>            : </a>
<a name="207"><span class="lineNum">     207 </span>            : template &lt;typename State, typename Element, typename Iteration, typename Lhs,</a>
<a name="208"><span class="lineNum">     208 </span>            :           typename Rhs, typename RhsWithOnlyLhs&gt;</a>
<a name="209"><span class="lineNum">     209 </span>            : struct generate_transformation_impl {</a>
<a name="210"><span class="lineNum">     210 </span>            :   using index_in_lhs = tmpl::index_of&lt;Lhs, Element&gt;;</a>
<a name="211"><span class="lineNum">     211 </span>            :   using type = tmpl::push_back&lt;State, typename generate_transformation_helper&lt;</a>
<a name="212"><span class="lineNum">     212 </span>            :                                           Element, Iteration, Lhs, Rhs,</a>
<a name="213"><span class="lineNum">     213 </span>            :                                           RhsWithOnlyLhs, index_in_lhs&gt;::type&gt;;</a>
<a name="214"><span class="lineNum">     214 </span>            : };</a>
<a name="215"><span class="lineNum">     215 </span>            : }  // namespace detail</a>
<a name="216"><span class="lineNum">     216 </span>            : </a>
<a name="217"><span class="lineNum">     217 </span>            : /// \ingroup TensorExpressionsGroup</a>
<a name="218"><span class="lineNum">     218 </span>            : /// \brief Generate transformation to account for index order difference in RHS</a>
<a name="219"><span class="lineNum">     219 </span>            : /// and LHS.</a>
<a name="220"><span class="lineNum">     220 </span>            : ///</a>
<a name="221"><span class="lineNum">     221 </span>            : /// \details</a>
<a name="222"><span class="lineNum">     222 </span>            : /// Generates the transformation \f$\mathcal{T}\f$ that rearranges the Tensor</a>
<a name="223"><span class="lineNum">     223 </span>            : /// index array to account for index order differences between the LHS and RHS</a>
<a name="224"><span class="lineNum">     224 </span>            : /// of the tensor expression.</a>
<a name="225"><span class="lineNum">     225 </span>            : ///</a>
<a name="226"><span class="lineNum">     226 </span>            : /// ### Usage</a>
<a name="227"><span class="lineNum">     227 </span>            : /// For typelists `Rhs`, `Lhs` and `RhsOnyWithLhs`, where `RhsOnlyWithLhs` is</a>
<a name="228"><span class="lineNum">     228 </span>            : /// the result of the metafunction rhs_elements_in_lhs,</a>
<a name="229"><span class="lineNum">     229 </span>            : /// \code{.cpp}</a>
<a name="230"><span class="lineNum">     230 </span>            : /// using result = generate_transformation&lt;Rhs, Lhs, RhsOnlyWithLhs&gt;;</a>
<a name="231"><span class="lineNum">     231 </span>            : /// \endcode</a>
<a name="232"><span class="lineNum">     232 </span>            : /// \metareturns</a>
<a name="233"><span class="lineNum">     233 </span>            : /// typelist</a>
<a name="234"><span class="lineNum">     234 </span>            : template &lt;typename Rhs, typename Lhs, typename RhsOnyWithLhs&gt;</a>
<a name="235"><span class="lineNum">     235 </span><span class="lineCov">          1 : using generate_transformation = tmpl::enumerated_fold&lt;</span></a>
<a name="236"><span class="lineNum">     236 </span>            :     Rhs, tmpl::list&lt;&gt;,</a>
<a name="237"><span class="lineNum">     237 </span>            :     detail::generate_transformation_impl&lt;tmpl::_state, tmpl::_element, tmpl::_3,</a>
<a name="238"><span class="lineNum">     238 </span>            :                                          tmpl::pin&lt;Lhs&gt;, tmpl::pin&lt;Rhs&gt;,</a>
<a name="239"><span class="lineNum">     239 </span>            :                                          tmpl::pin&lt;RhsOnyWithLhs&gt;&gt;&gt;;</a>
<a name="240"><span class="lineNum">     240 </span>            : </a>
<a name="241"><span class="lineNum">     241 </span>            : /// \ingroup TensorExpressionsGroup</a>
<a name="242"><span class="lineNum">     242 </span>            : /// \brief Marks a class as being a TensorExpression</a>
<a name="243"><span class="lineNum">     243 </span>            : ///</a>
<a name="244"><span class="lineNum">     244 </span>            : /// \details</a>
<a name="245"><span class="lineNum">     245 </span>            : /// The empty base class that all TensorExpression`s must inherit from.</a>
<a name="246"><span class="lineNum">     246 </span>            : /// \derivedrequires</a>
<a name="247"><span class="lineNum">     247 </span>            : /// 1) The args_list will be the sorted args_list received as input</a>
<a name="248"><span class="lineNum">     248 </span>            : ///</a>
<a name="249"><span class="lineNum">     249 </span>            : /// 2) The tensor indices will be swapped to conform with mathematical notation</a>
<a name="250"><span class="lineNum">     250 </span><span class="lineCov">          1 : struct Expression {};</span></a>
<a name="251"><span class="lineNum">     251 </span>            : </a>
<a name="252"><span class="lineNum">     252 </span>            : /// \cond</a>
<a name="253"><span class="lineNum">     253 </span>            : template &lt;typename DataType, typename Symm, typename IndexList&gt;</a>
<a name="254"><span class="lineNum">     254 </span>            : class Tensor;</a>
<a name="255"><span class="lineNum">     255 </span>            : /// \endcond</a>
<a name="256"><span class="lineNum">     256 </span>            : </a>
<a name="257"><span class="lineNum">     257 </span>            : // @{</a>
<a name="258"><span class="lineNum">     258 </span>            : /// \ingroup TensorExpressionsGroup</a>
<a name="259"><span class="lineNum">     259 </span>            : /// \brief The base class all tensor expression implementations derive from</a>
<a name="260"><span class="lineNum">     260 </span>            : ///</a>
<a name="261"><span class="lineNum">     261 </span>            : /// \tparam Derived the derived class needed for</a>
<a name="262"><span class="lineNum">     262 </span>            : /// [CRTP](https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern)</a>
<a name="263"><span class="lineNum">     263 </span>            : /// \tparam DataType the type of the data being stored in the Tensor's</a>
<a name="264"><span class="lineNum">     264 </span>            : /// \tparam Symm the ::Symmetry of the Derived class</a>
<a name="265"><span class="lineNum">     265 </span>            : /// \tparam IndexList the list of \ref SpacetimeIndex &quot;TensorIndex&quot;'s</a>
<a name="266"><span class="lineNum">     266 </span>            : /// \tparam Args the tensor indices, e.g. `_a` and `_b` in `F(_a, _b)`</a>
<a name="267"><span class="lineNum">     267 </span>            : /// \cond HIDDEN_SYMBOLS</a>
<a name="268"><span class="lineNum">     268 </span>            : template &lt;typename Derived, typename DataType, typename Symm,</a>
<a name="269"><span class="lineNum">     269 </span>            :           typename IndexList, typename Args = tmpl::list&lt;&gt;,</a>
<a name="270"><span class="lineNum">     270 </span>            :           typename ReducedArgs = tmpl::list&lt;&gt;&gt;</a>
<a name="271"><span class="lineNum">     271 </span>            : struct TensorExpression;</a>
<a name="272"><span class="lineNum">     272 </span>            : /// \endcond</a>
<a name="273"><span class="lineNum">     273 </span>            : </a>
<a name="274"><span class="lineNum">     274 </span>            : template &lt;typename Derived, typename DataType, typename Symm,</a>
<a name="275"><span class="lineNum">     275 </span>            :           typename... Indices, template &lt;typename...&gt; class ArgsList,</a>
<a name="276"><span class="lineNum">     276 </span>            :           typename... Args&gt;</a>
<a name="277"><span class="lineNum">     277 </span>            : struct TensorExpression&lt;Derived, DataType, Symm, tmpl::list&lt;Indices...&gt;,</a>
<a name="278"><span class="lineNum">     278 </span><span class="lineCov">          1 :                         ArgsList&lt;Args...&gt;&gt; : public Expression {</span></a>
<a name="279"><span class="lineNum">     279 </span>            :   static_assert(sizeof...(Args) == 0 or sizeof...(Args) == sizeof...(Indices),</a>
<a name="280"><span class="lineNum">     280 </span>            :                 &quot;the number of Tensor indices must match the number of &quot;</a>
<a name="281"><span class="lineNum">     281 </span>            :                 &quot;components specified in an expression.&quot;);</a>
<a name="282"><span class="lineNum">     282 </span><span class="lineNoCov">          0 :   using type = DataType;</span></a>
<a name="283"><span class="lineNum">     283 </span><span class="lineNoCov">          0 :   using symmetry = Symm;</span></a>
<a name="284"><span class="lineNum">     284 </span><span class="lineNoCov">          0 :   using index_list = tmpl::list&lt;Indices...&gt;;</span></a>
<a name="285"><span class="lineNum">     285 </span><span class="lineNoCov">          0 :   static constexpr auto num_tensor_indices = tmpl::size&lt;index_list&gt;::value;</span></a>
<a name="286"><span class="lineNum">     286 </span>            :   /// Typelist of the tensor indices, e.g. `_a_t` and `_b_t` in `F(_a, _b)`</a>
<a name="287"><span class="lineNum">     287 </span><span class="lineCov">          1 :   using args_list = ArgsList&lt;Args...&gt;;</span></a>
<a name="288"><span class="lineNum">     288 </span><span class="lineNoCov">          0 :   using structure = Tensor_detail::Structure&lt;symmetry, Indices...&gt;;</span></a>
<a name="289"><span class="lineNum">     289 </span>            : </a>
<a name="290"><span class="lineNum">     290 </span>            :   // @{</a>
<a name="291"><span class="lineNum">     291 </span>            :   /// If Derived is a TensorExpression, it is casted down to the derived</a>
<a name="292"><span class="lineNum">     292 </span>            :   /// class. This is enabled by the</a>
<a name="293"><span class="lineNum">     293 </span>            :   /// [CRTP](https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern)</a>
<a name="294"><span class="lineNum">     294 </span>            :   ///</a>
<a name="295"><span class="lineNum">     295 </span>            :   /// Otherwise, it is a Tensor. Since Tensor is not derived from</a>
<a name="296"><span class="lineNum">     296 </span>            :   /// TensorExpression (because of complications arising from the indices being</a>
<a name="297"><span class="lineNum">     297 </span>            :   /// part of the expression, specifically Tensor may need to derive off of</a>
<a name="298"><span class="lineNum">     298 </span>            :   /// hundreds or thousands of base classes, which is not feasible), return a</a>
<a name="299"><span class="lineNum">     299 </span>            :   /// reference to a TensorExpression, which has a sufficient interface to</a>
<a name="300"><span class="lineNum">     300 </span>            :   /// evaluate the expression.</a>
<a name="301"><span class="lineNum">     301 </span>            :   ///</a>
<a name="302"><span class="lineNum">     302 </span>            :   /// \returns const TensorExpression&lt;Derived, DataType, Symm, IndexList,</a>
<a name="303"><span class="lineNum">     303 </span>            :   /// ArgsList&lt;Args...&gt;&gt;&amp;</a>
<a name="304"><span class="lineNum">     304 </span><span class="lineCov">          1 :   SPECTRE_ALWAYS_INLINE const auto&amp; operator~() const noexcept {</span></a>
<a name="305"><span class="lineNum">     305 </span>            :     if constexpr (tt::is_a_v&lt;Tensor, Derived&gt;) {</a>
<a name="306"><span class="lineNum">     306 </span>            :       return *this;</a>
<a name="307"><span class="lineNum">     307 </span>            :     } else {</a>
<a name="308"><span class="lineNum">     308 </span>            :       return static_cast&lt;const Derived&amp;&gt;(*this);</a>
<a name="309"><span class="lineNum">     309 </span>            :     }</a>
<a name="310"><span class="lineNum">     310 </span>            :   }</a>
<a name="311"><span class="lineNum">     311 </span>            : </a>
<a name="312"><span class="lineNum">     312 </span>            :   // @}</a>
<a name="313"><span class="lineNum">     313 </span>            : </a>
<a name="314"><span class="lineNum">     314 </span>            :   // @{</a>
<a name="315"><span class="lineNum">     315 </span>            :   /// \cond HIDDEN_SYMBOLS</a>
<a name="316"><span class="lineNum">     316 </span>            :   /// \ingroup TensorExpressionsGroup</a>
<a name="317"><span class="lineNum">     317 </span>            :   /// Helper struct to compute the correct tensor index array from a</a>
<a name="318"><span class="lineNum">     318 </span>            :   /// typelist of std::integral_constant's indicating the ordering. This is</a>
<a name="319"><span class="lineNum">     319 </span>            :   /// needed for dealing with expressions such as \f$T_{ab} = F_{ba}\f$ and gets</a>
<a name="320"><span class="lineNum">     320 </span>            :   /// the ordering on the RHS to be correct compared with where the indices are</a>
<a name="321"><span class="lineNum">     321 </span>            :   /// on the LHS.</a>
<a name="322"><span class="lineNum">     322 </span>            :   template &lt;typename U&gt;</a>
<a name="323"><span class="lineNum">     323 </span>            :   struct ComputeCorrectTensorIndex;</a>
<a name="324"><span class="lineNum">     324 </span>            : </a>
<a name="325"><span class="lineNum">     325 </span>            :   template &lt;template &lt;typename...&gt; class RedArgsList, typename... RedArgs&gt;</a>
<a name="326"><span class="lineNum">     326 </span>            :   struct ComputeCorrectTensorIndex&lt;RedArgsList&lt;RedArgs...&gt;&gt; {</a>
<a name="327"><span class="lineNum">     327 </span>            :     template &lt;typename U, std::size_t Size&gt;</a>
<a name="328"><span class="lineNum">     328 </span>            :     SPECTRE_ALWAYS_INLINE static constexpr std::array&lt;U, Size&gt; apply(</a>
<a name="329"><span class="lineNum">     329 </span>            :         const std::array&lt;U, Size&gt;&amp; tensor_index) {</a>
<a name="330"><span class="lineNum">     330 </span>            :       return std::array&lt;U, Size&gt;{{tensor_index[RedArgs::value]...}};</a>
<a name="331"><span class="lineNum">     331 </span>            :     }</a>
<a name="332"><span class="lineNum">     332 </span>            :   };</a>
<a name="333"><span class="lineNum">     333 </span>            :   /// \endcond</a>
<a name="334"><span class="lineNum">     334 </span>            :   // @}</a>
<a name="335"><span class="lineNum">     335 </span>            : </a>
<a name="336"><span class="lineNum">     336 </span>            :   /// \brief return the value of type DataType with tensor index `tensor_index`</a>
<a name="337"><span class="lineNum">     337 </span>            :   ///</a>
<a name="338"><span class="lineNum">     338 </span>            :   /// \details</a>
<a name="339"><span class="lineNum">     339 </span>            :   /// If Derived is a TensorExpression, `tensor_index` is forwarded onto the</a>
<a name="340"><span class="lineNum">     340 </span>            :   /// concrete derived TensorExpression.</a>
<a name="341"><span class="lineNum">     341 </span>            :   ///</a>
<a name="342"><span class="lineNum">     342 </span>            :   /// Otherwise, it is a Tensor, where one big challenge with TensorExpression</a>
<a name="343"><span class="lineNum">     343 </span>            :   /// implementation is the reordering of the Indices on the RHS and LHS of the</a>
<a name="344"><span class="lineNum">     344 </span>            :   /// expression. This algorithm implemented in ::rhs_elements_in_lhs and</a>
<a name="345"><span class="lineNum">     345 </span>            :   /// ::generate_transformation handles the index sorting.</a>
<a name="346"><span class="lineNum">     346 </span>            :   ///</a>
<a name="347"><span class="lineNum">     347 </span>            :   /// Here are some examples of what the algorithm does:</a>
<a name="348"><span class="lineNum">     348 </span>            :   ///</a>
<a name="349"><span class="lineNum">     349 </span>            :   /// LhsIndices is the desired ordering.</a>
<a name="350"><span class="lineNum">     350 </span>            :   ///</a>
<a name="351"><span class="lineNum">     351 </span>            :   /// LHS:</a>
<a name="352"><span class="lineNum">     352 </span>            :   /// \code</a>
<a name="353"><span class="lineNum">     353 </span>            :   /// &lt;0, 1&gt;</a>
<a name="354"><span class="lineNum">     354 </span>            :   /// \endcode</a>
<a name="355"><span class="lineNum">     355 </span>            :   /// RHS:</a>
<a name="356"><span class="lineNum">     356 </span>            :   /// \code</a>
<a name="357"><span class="lineNum">     357 </span>            :   /// &lt;1, 2, 3, 0&gt; -Transform&gt; &lt;3, 1, 2, 0&gt;</a>
<a name="358"><span class="lineNum">     358 </span>            :   /// \endcode</a>
<a name="359"><span class="lineNum">     359 </span>            :   ///</a>
<a name="360"><span class="lineNum">     360 </span>            :   /// LHS:</a>
<a name="361"><span class="lineNum">     361 </span>            :   /// \code</a>
<a name="362"><span class="lineNum">     362 </span>            :   /// &lt;0, 1, 2&gt; &lt;a, b, c&gt;</a>
<a name="363"><span class="lineNum">     363 </span>            :   /// \endcode</a>
<a name="364"><span class="lineNum">     364 </span>            :   /// RHS:</a>
<a name="365"><span class="lineNum">     365 </span>            :   /// \code</a>
<a name="366"><span class="lineNum">     366 </span>            :   /// &lt;2, 0, 1&gt; -Transform&gt; &lt;2 , 1, 0&gt;</a>
<a name="367"><span class="lineNum">     367 </span>            :   /// \endcode</a>
<a name="368"><span class="lineNum">     368 </span>            :   ///</a>
<a name="369"><span class="lineNum">     369 </span>            :   /// Below is pseudo-code of the algorithm written in a non-functional way</a>
<a name="370"><span class="lineNum">     370 </span>            :   /// \verbatim</a>
<a name="371"><span class="lineNum">     371 </span>            :   /// for Element in RHS:</a>
<a name="372"><span class="lineNum">     372 </span>            :   ///   if (Element in LHS):</a>
<a name="373"><span class="lineNum">     373 </span>            :   ///     index_in_LHS = index_of&lt;LHS, Element&gt;</a>
<a name="374"><span class="lineNum">     374 </span>            :   ///     tensor_index_to_find = at&lt;RHS_with_only_LHS, index_in_LHS&gt;</a>
<a name="375"><span class="lineNum">     375 </span>            :   ///     index_to_replace_with = index_of&lt;RHS, tensor_index_to_find&gt;</a>
<a name="376"><span class="lineNum">     376 </span>            :   ///     T_RHS = push_back&lt;T_RHS, index_to_replace_with&gt;</a>
<a name="377"><span class="lineNum">     377 </span>            :   ///   else:</a>
<a name="378"><span class="lineNum">     378 </span>            :   ///     T_RHS = push_back&lt;T_RHS, iteration&gt;</a>
<a name="379"><span class="lineNum">     379 </span>            :   ///   endif</a>
<a name="380"><span class="lineNum">     380 </span>            :   /// end for</a>
<a name="381"><span class="lineNum">     381 </span>            :   /// \endverbatim</a>
<a name="382"><span class="lineNum">     382 </span>            :   ///</a>
<a name="383"><span class="lineNum">     383 </span>            :   /// \tparam LhsIndices the tensor indices on the LHS on the expression</a>
<a name="384"><span class="lineNum">     384 </span>            :   /// \param tensor_index the tensor component to retrieve</a>
<a name="385"><span class="lineNum">     385 </span>            :   /// \return the value of the DataType of component `tensor_index`</a>
<a name="386"><span class="lineNum">     386 </span>            :   template &lt;typename... LhsIndices, typename ArrayValueType&gt;</a>
<a name="387"><span class="lineNum">     387 </span>            :   SPECTRE_ALWAYS_INLINE decltype(auto)</a>
<a name="388"><span class="lineNum">     388 </span><span class="lineCov">          1 :   get(const std::array&lt;ArrayValueType, num_tensor_indices&gt;&amp; tensor_index)</span></a>
<a name="389"><span class="lineNum">     389 </span>            :       const noexcept {</a>
<a name="390"><span class="lineNum">     390 </span>            :     if constexpr (tt::is_a_v&lt;Tensor, Derived&gt;) {</a>
<a name="391"><span class="lineNum">     391 </span>            :       ASSERT(t_ != nullptr,</a>
<a name="392"><span class="lineNum">     392 </span>            :              &quot;A TensorExpression that should be holding a pointer to a Tensor &quot;</a>
<a name="393"><span class="lineNum">     393 </span>            :              &quot;is holding a nullptr.&quot;);</a>
<a name="394"><span class="lineNum">     394 </span>            :       using rhs = args_list;</a>
<a name="395"><span class="lineNum">     395 </span>            :       // To deal with Tensor products we need the ordering of only the subset of</a>
<a name="396"><span class="lineNum">     396 </span>            :       // tensor indices present in this term</a>
<a name="397"><span class="lineNum">     397 </span>            :       using lhs = rhs_elements_in_lhs&lt;rhs, tmpl::list&lt;LhsIndices...&gt;&gt;;</a>
<a name="398"><span class="lineNum">     398 </span>            :       using rhs_only_with_lhs = rhs_elements_in_lhs&lt;lhs, rhs&gt;;</a>
<a name="399"><span class="lineNum">     399 </span>            :       using transformation =</a>
<a name="400"><span class="lineNum">     400 </span>            :           generate_transformation&lt;rhs, lhs, rhs_only_with_lhs&gt;;</a>
<a name="401"><span class="lineNum">     401 </span>            :       return t_-&gt;get(</a>
<a name="402"><span class="lineNum">     402 </span>            :           ComputeCorrectTensorIndex&lt;transformation&gt;::apply(tensor_index));</a>
<a name="403"><span class="lineNum">     403 </span>            :     } else {</a>
<a name="404"><span class="lineNum">     404 </span>            :       ASSERT(t_ == nullptr,</a>
<a name="405"><span class="lineNum">     405 </span>            :              &quot;A TensorExpression that shouldn't be holding a pointer to a &quot;</a>
<a name="406"><span class="lineNum">     406 </span>            :              &quot;Tensor is holding one.&quot;);</a>
<a name="407"><span class="lineNum">     407 </span>            :       return (~*this).template get&lt;LhsIndices...&gt;(tensor_index);</a>
<a name="408"><span class="lineNum">     408 </span>            :     }</a>
<a name="409"><span class="lineNum">     409 </span>            :   }</a>
<a name="410"><span class="lineNum">     410 </span>            : </a>
<a name="411"><span class="lineNum">     411 </span>            :   /// \brief Computes the right hand side tensor multi-index that corresponds to</a>
<a name="412"><span class="lineNum">     412 </span>            :   /// the left hand side tensor multi-index, according to their generic indices</a>
<a name="413"><span class="lineNum">     413 </span>            :   ///</a>
<a name="414"><span class="lineNum">     414 </span>            :   /// \details</a>
<a name="415"><span class="lineNum">     415 </span>            :   /// Given the order of the generic indices for the left hand side (LHS) and</a>
<a name="416"><span class="lineNum">     416 </span>            :   /// right hand side (RHS) and a specific LHS tensor multi-index, the</a>
<a name="417"><span class="lineNum">     417 </span>            :   /// computation of the equivalent multi-index for the RHS tensor accounts for</a>
<a name="418"><span class="lineNum">     418 </span>            :   /// differences in the ordering of the generic indices on the LHS and RHS.</a>
<a name="419"><span class="lineNum">     419 </span>            :   ///</a>
<a name="420"><span class="lineNum">     420 </span>            :   /// Here, the elements of `lhs_index_order` and `rhs_index_order` refer to</a>
<a name="421"><span class="lineNum">     421 </span>            :   /// TensorIndex::values that correspond to generic tensor indices,</a>
<a name="422"><span class="lineNum">     422 </span>            :   /// `lhs_tensor_multi_index` is a multi-index for the LHS tensor, and the</a>
<a name="423"><span class="lineNum">     423 </span>            :   /// equivalent RHS tensor multi-index is returned. If we have LHS tensor</a>
<a name="424"><span class="lineNum">     424 </span>            :   /// \f$L_{ab}\f$, RHS tensor \f$R_{ba}\f$, and the LHS component \f$L_{31}\f$,</a>
<a name="425"><span class="lineNum">     425 </span>            :   /// the corresponding RHS component is \f$R_{13}\f$.</a>
<a name="426"><span class="lineNum">     426 </span>            :   ///</a>
<a name="427"><span class="lineNum">     427 </span>            :   /// Here is an example of what the algorithm does:</a>
<a name="428"><span class="lineNum">     428 </span>            :   ///</a>
<a name="429"><span class="lineNum">     429 </span>            :   /// `lhs_index_order`:</a>
<a name="430"><span class="lineNum">     430 </span>            :   /// \code</a>
<a name="431"><span class="lineNum">     431 </span>            :   /// [0, 1, 2] // i.e. abc</a>
<a name="432"><span class="lineNum">     432 </span>            :   /// \endcode</a>
<a name="433"><span class="lineNum">     433 </span>            :   /// `rhs_index_order`:</a>
<a name="434"><span class="lineNum">     434 </span>            :   /// \code</a>
<a name="435"><span class="lineNum">     435 </span>            :   /// [1, 2, 0] // i.e. bca</a>
<a name="436"><span class="lineNum">     436 </span>            :   /// \endcode</a>
<a name="437"><span class="lineNum">     437 </span>            :   /// `lhs_tensor_multi_index`:</a>
<a name="438"><span class="lineNum">     438 </span>            :   /// \code</a>
<a name="439"><span class="lineNum">     439 </span>            :   /// [4, 0, 3] // i.e. a = 4, b = 0, c = 3</a>
<a name="440"><span class="lineNum">     440 </span>            :   /// \endcode</a>
<a name="441"><span class="lineNum">     441 </span>            :   /// returned RHS tensor multi-index:</a>
<a name="442"><span class="lineNum">     442 </span>            :   /// \code</a>
<a name="443"><span class="lineNum">     443 </span>            :   /// [0, 3, 4] // i.e. b = 0, c = 3, a = 4</a>
<a name="444"><span class="lineNum">     444 </span>            :   /// \endcode</a>
<a name="445"><span class="lineNum">     445 </span>            :   ///</a>
<a name="446"><span class="lineNum">     446 </span>            :   /// \param lhs_index_order the generic index order of the LHS tensor</a>
<a name="447"><span class="lineNum">     447 </span>            :   /// \param rhs_index_order the generic index order of the RHS tensor</a>
<a name="448"><span class="lineNum">     448 </span>            :   /// \param lhs_tensor_multi_index the specific LHS tensor multi-index</a>
<a name="449"><span class="lineNum">     449 </span>            :   /// \return the RHS tensor multi-index that corresponds to</a>
<a name="450"><span class="lineNum">     450 </span>            :   /// `lhs_tensor_multi_index`, according to the index orders in</a>
<a name="451"><span class="lineNum">     451 </span>            :   /// `lhs_index_order` and `rhs_index_order`</a>
<a name="452"><span class="lineNum">     452 </span>            :   SPECTRE_ALWAYS_INLINE static constexpr std::array&lt;size_t, sizeof...(Indices)&gt;</a>
<a name="453"><span class="lineNum">     453 </span><span class="lineCov">          1 :   compute_rhs_tensor_index(</span></a>
<a name="454"><span class="lineNum">     454 </span>            :       const std::array&lt;size_t, sizeof...(Indices)&gt;&amp; lhs_index_order,</a>
<a name="455"><span class="lineNum">     455 </span>            :       const std::array&lt;size_t, sizeof...(Indices)&gt;&amp; rhs_index_order,</a>
<a name="456"><span class="lineNum">     456 </span>            :       const std::array&lt;size_t, sizeof...(Indices)&gt;&amp;</a>
<a name="457"><span class="lineNum">     457 </span>            :           lhs_tensor_multi_index) noexcept {</a>
<a name="458"><span class="lineNum">     458 </span>            :     std::array&lt;size_t, sizeof...(Indices)&gt; rhs_tensor_multi_index{};</a>
<a name="459"><span class="lineNum">     459 </span>            :     for (size_t i = 0; i &lt; sizeof...(Indices); ++i) {</a>
<a name="460"><span class="lineNum">     460 </span>            :       gsl::at(rhs_tensor_multi_index,</a>
<a name="461"><span class="lineNum">     461 </span>            :               static_cast&lt;unsigned long&gt;(std::distance(</a>
<a name="462"><span class="lineNum">     462 </span>            :                   rhs_index_order.begin(),</a>
<a name="463"><span class="lineNum">     463 </span>            :                   alg::find(rhs_index_order, gsl::at(lhs_index_order, i))))) =</a>
<a name="464"><span class="lineNum">     464 </span>            :           gsl::at(lhs_tensor_multi_index, i);</a>
<a name="465"><span class="lineNum">     465 </span>            :     }</a>
<a name="466"><span class="lineNum">     466 </span>            :     return rhs_tensor_multi_index;</a>
<a name="467"><span class="lineNum">     467 </span>            :   }</a>
<a name="468"><span class="lineNum">     468 </span>            : </a>
<a name="469"><span class="lineNum">     469 </span>            :   /// \brief Computes a mapping from the storage indices of the left hand side</a>
<a name="470"><span class="lineNum">     470 </span>            :   /// tensor to the right hand side tensor</a>
<a name="471"><span class="lineNum">     471 </span>            :   ///</a>
<a name="472"><span class="lineNum">     472 </span>            :   /// \tparam LhsStructure the Structure of the Tensor on the left hand side of</a>
<a name="473"><span class="lineNum">     473 </span>            :   /// the TensorExpression</a>
<a name="474"><span class="lineNum">     474 </span>            :   /// \tparam LhsIndices the TensorIndexs of the Tensor on the left hand side</a>
<a name="475"><span class="lineNum">     475 </span>            :   /// \return the mapping from the left hand side to the right hand side storage</a>
<a name="476"><span class="lineNum">     476 </span>            :   /// indices</a>
<a name="477"><span class="lineNum">     477 </span>            :   template &lt;typename LhsStructure, typename... LhsIndices&gt;</a>
<a name="478"><span class="lineNum">     478 </span>            :   SPECTRE_ALWAYS_INLINE static constexpr std::array&lt;size_t,</a>
<a name="479"><span class="lineNum">     479 </span>            :                                                     LhsStructure::size()&gt;</a>
<a name="480"><span class="lineNum">     480 </span><span class="lineCov">          1 :   compute_lhs_to_rhs_map() noexcept {</span></a>
<a name="481"><span class="lineNum">     481 </span>            :     constexpr size_t num_components = LhsStructure::size();</a>
<a name="482"><span class="lineNum">     482 </span>            :     std::array&lt;size_t, num_components&gt; lhs_to_rhs_map{};</a>
<a name="483"><span class="lineNum">     483 </span>            :     const auto lhs_storage_to_tensor_indices =</a>
<a name="484"><span class="lineNum">     484 </span>            :         LhsStructure::storage_to_tensor_index();</a>
<a name="485"><span class="lineNum">     485 </span>            :     for (size_t lhs_storage_index = 0; lhs_storage_index &lt; num_components;</a>
<a name="486"><span class="lineNum">     486 </span>            :          ++lhs_storage_index) {</a>
<a name="487"><span class="lineNum">     487 </span>            :       // `compute_rhs_tensor_index` will return the RHS tensor multi-index that</a>
<a name="488"><span class="lineNum">     488 </span>            :       // corresponds to the LHS tensor multi-index, according to the order of</a>
<a name="489"><span class="lineNum">     489 </span>            :       // the generic indices for the LHS and RHS. structure::get_storage_index</a>
<a name="490"><span class="lineNum">     490 </span>            :       // will then get the RHS storage index that corresponds to this RHS</a>
<a name="491"><span class="lineNum">     491 </span>            :       // tensor multi-index.</a>
<a name="492"><span class="lineNum">     492 </span>            :       gsl::at(lhs_to_rhs_map, lhs_storage_index) =</a>
<a name="493"><span class="lineNum">     493 </span>            :           structure::get_storage_index(compute_rhs_tensor_index(</a>
<a name="494"><span class="lineNum">     494 </span>            :               {{LhsIndices::value...}}, {{Args::value...}},</a>
<a name="495"><span class="lineNum">     495 </span>            :               lhs_storage_to_tensor_indices[lhs_storage_index]));</a>
<a name="496"><span class="lineNum">     496 </span>            :     }</a>
<a name="497"><span class="lineNum">     497 </span>            :     return lhs_to_rhs_map;</a>
<a name="498"><span class="lineNum">     498 </span>            :   }</a>
<a name="499"><span class="lineNum">     499 </span>            : </a>
<a name="500"><span class="lineNum">     500 </span>            :   /// \brief return the value at a left hand side tensor's storage index</a>
<a name="501"><span class="lineNum">     501 </span>            :   ///</a>
<a name="502"><span class="lineNum">     502 </span>            :   /// \details</a>
<a name="503"><span class="lineNum">     503 </span>            :   /// If Derived is a TensorExpression, `storage_index` is forwarded onto the</a>
<a name="504"><span class="lineNum">     504 </span>            :   /// concrete derived TensorExpression.</a>
<a name="505"><span class="lineNum">     505 </span>            :   ///</a>
<a name="506"><span class="lineNum">     506 </span>            :   /// Otherwise, it is a Tensor, where one big challenge with TensorExpression</a>
<a name="507"><span class="lineNum">     507 </span>            :   /// implementation is the reordering of the indices on the left hand side</a>
<a name="508"><span class="lineNum">     508 </span>            :   /// (LHS) and right hand side (RHS) of the expression. The algorithms</a>
<a name="509"><span class="lineNum">     509 </span>            :   /// implemented in `compute_lhs_to_rhs_map` and `compute_rhs_tensor_index`</a>
<a name="510"><span class="lineNum">     510 </span>            :   /// handle the index sorting by mapping between the generic index orders of</a>
<a name="511"><span class="lineNum">     511 </span>            :   /// the LHS and RHS.</a>
<a name="512"><span class="lineNum">     512 </span>            :   ///</a>
<a name="513"><span class="lineNum">     513 </span>            :   /// \tparam LhsStructure the Structure of the Tensor on the LHS of the</a>
<a name="514"><span class="lineNum">     514 </span>            :   /// TensorExpression</a>
<a name="515"><span class="lineNum">     515 </span>            :   /// \tparam LhsIndices the TensorIndexs of the Tensor on the LHS of the tensor</a>
<a name="516"><span class="lineNum">     516 </span>            :   /// expression</a>
<a name="517"><span class="lineNum">     517 </span>            :   /// \param lhs_storage_index the storage index of the LHS tensor component to</a>
<a name="518"><span class="lineNum">     518 </span>            :   /// retrieve</a>
<a name="519"><span class="lineNum">     519 </span>            :   /// \return the value of the DataType of the component at `lhs_storage_index`</a>
<a name="520"><span class="lineNum">     520 </span>            :   /// in the LHS tensor</a>
<a name="521"><span class="lineNum">     521 </span>            :   template &lt;typename LhsStructure, typename... LhsIndices&gt;</a>
<a name="522"><span class="lineNum">     522 </span>            :   SPECTRE_ALWAYS_INLINE decltype(auto)</a>
<a name="523"><span class="lineNum">     523 </span><span class="lineCov">          1 :   get(const size_t lhs_storage_index) const noexcept {</span></a>
<a name="524"><span class="lineNum">     524 </span>            :     if constexpr (not tt::is_a_v&lt;Tensor, Derived&gt;) {</a>
<a name="525"><span class="lineNum">     525 </span>            :       return static_cast&lt;const Derived&amp;&gt;(*this)</a>
<a name="526"><span class="lineNum">     526 </span>            :           .template get&lt;LhsStructure, LhsIndices...&gt;(lhs_storage_index);</a>
<a name="527"><span class="lineNum">     527 </span>            :     } else if constexpr (std::is_same_v&lt;LhsStructure, structure&gt; and</a>
<a name="528"><span class="lineNum">     528 </span>            :                          std::is_same_v&lt;tmpl::list&lt;LhsIndices...&gt;,</a>
<a name="529"><span class="lineNum">     529 </span>            :                                         tmpl::list&lt;Args...&gt;&gt;) {</a>
<a name="530"><span class="lineNum">     530 </span>            :       // the LHS and RHS tensors have the same structure and generic index</a>
<a name="531"><span class="lineNum">     531 </span>            :       // order, so the RHS storage index is equivalent to the LHS storage index</a>
<a name="532"><span class="lineNum">     532 </span>            :       return (*t_)[lhs_storage_index];</a>
<a name="533"><span class="lineNum">     533 </span>            :     } else {</a>
<a name="534"><span class="lineNum">     534 </span>            :       // the LHS and RHS tensors do not have the same structure or generic index</a>
<a name="535"><span class="lineNum">     535 </span>            :       // order, so we must map the LHS storage index to its corresponding RHS</a>
<a name="536"><span class="lineNum">     536 </span>            :       // storage index</a>
<a name="537"><span class="lineNum">     537 </span>            :       constexpr std::array&lt;size_t, LhsStructure::size()&gt; lhs_to_rhs_map =</a>
<a name="538"><span class="lineNum">     538 </span>            :           compute_lhs_to_rhs_map&lt;LhsStructure, LhsIndices...&gt;();</a>
<a name="539"><span class="lineNum">     539 </span>            :       return (*t_)[gsl::at(lhs_to_rhs_map, lhs_storage_index)];</a>
<a name="540"><span class="lineNum">     540 </span>            :     }</a>
<a name="541"><span class="lineNum">     541 </span>            :   }</a>
<a name="542"><span class="lineNum">     542 </span>            : </a>
<a name="543"><span class="lineNum">     543 </span>            :   /// Retrieve the i'th entry of the Tensor being held</a>
<a name="544"><span class="lineNum">     544 </span>            :   template &lt;typename V = Derived,</a>
<a name="545"><span class="lineNum">     545 </span>            :             Requires&lt;tt::is_a&lt;Tensor, V&gt;::value&gt; = nullptr&gt;</a>
<a name="546"><span class="lineNum">     546 </span><span class="lineCov">          1 :   SPECTRE_ALWAYS_INLINE type operator[](const size_t i) const {</span></a>
<a name="547"><span class="lineNum">     547 </span>            :     return t_-&gt;operator[](i);</a>
<a name="548"><span class="lineNum">     548 </span>            :   }</a>
<a name="549"><span class="lineNum">     549 </span>            : </a>
<a name="550"><span class="lineNum">     550 </span>            :   /// \brief Construct a TensorExpression from another TensorExpression.</a>
<a name="551"><span class="lineNum">     551 </span>            :   ///</a>
<a name="552"><span class="lineNum">     552 </span>            :   /// In this case we do not need to store a pointer to the TensorExpression</a>
<a name="553"><span class="lineNum">     553 </span>            :   /// since we can cast back to the derived class using operator~.</a>
<a name="554"><span class="lineNum">     554 </span>            :   template &lt;typename V = Derived,</a>
<a name="555"><span class="lineNum">     555 </span>            :             Requires&lt;not tt::is_a&lt;Tensor, V&gt;::value&gt; = nullptr&gt;</a>
<a name="556"><span class="lineNum">     556 </span><span class="lineCov">          1 :   TensorExpression() {}  // NOLINT</span></a>
<a name="557"><span class="lineNum">     557 </span>            : </a>
<a name="558"><span class="lineNum">     558 </span>            :   /// \brief Construct a TensorExpression from a Tensor.</a>
<a name="559"><span class="lineNum">     559 </span>            :   ///</a>
<a name="560"><span class="lineNum">     560 </span>            :   /// We need to store a pointer to the Tensor in a member variable in order</a>
<a name="561"><span class="lineNum">     561 </span>            :   /// to be able to access the data when later evaluating the tensor expression.</a>
<a name="562"><span class="lineNum">     562 </span><span class="lineCov">          1 :   explicit TensorExpression(const Tensor&lt;DataType, Symm, index_list&gt;&amp; t)</span></a>
<a name="563"><span class="lineNum">     563 </span>            :       : t_(&amp;t) {}</a>
<a name="564"><span class="lineNum">     564 </span>            : </a>
<a name="565"><span class="lineNum">     565 </span>            :  private:</a>
<a name="566"><span class="lineNum">     566 </span>            :   /// Holds a pointer to a Tensor if the TensorExpression represents one.</a>
<a name="567"><span class="lineNum">     567 </span>            :   ///</a>
<a name="568"><span class="lineNum">     568 </span>            :   /// The pointer is needed so that the Tensor class need not derive from</a>
<a name="569"><span class="lineNum">     569 </span>            :   /// TensorExpression. The reason deriving off of TensorExpression is</a>
<a name="570"><span class="lineNum">     570 </span>            :   /// problematic for Tensor is that the index structure is part of the type</a>
<a name="571"><span class="lineNum">     571 </span>            :   /// of the TensorExpression, so every possible permutation and combination of</a>
<a name="572"><span class="lineNum">     572 </span>            :   /// indices must be derived from. For a rank-3 tensor this is already over 500</a>
<a name="573"><span class="lineNum">     573 </span>            :   /// base classes, which the Intel compiler takes too long to compile.</a>
<a name="574"><span class="lineNum">     574 </span>            :   ///</a>
<a name="575"><span class="lineNum">     575 </span>            :   /// Benchmarking shows that GCC 6 and Clang 3.9.0 can derive off of 672 base</a>
<a name="576"><span class="lineNum">     576 </span>            :   /// classes with compilation time of about 5 seconds, while the Intel compiler</a>
<a name="577"><span class="lineNum">     577 </span>            :   /// v16.3 takes around 8 minutes. These tests were done on a Haswell Core i5.</a>
<a name="578"><span class="lineNum">     578 </span><span class="lineCov">          1 :   const Derived* t_ = nullptr;</span></a>
<a name="579"><span class="lineNum">     579 </span>            : };</a>
<a name="580"><span class="lineNum">     580 </span>            : // @}</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
